{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg = pd.read_csv(\"/data/negative.csv\")\n",
    "pos = pd.read_csv(\"/data/positive.csv\")\n",
    "neg_df = pd.DataFrame(neg)\n",
    "pos_df = pd.DataFrame(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_drop_df = neg_df.drop_duplicates(inplace = False)\n",
    "pos_drop_df = pos_df.drop_duplicates(inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_df = neg_df.sample(n=25000)\n",
    "pos_df = pos_df.sample(n=25000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_df.head()\n",
    "neg_df = neg_df.rename(columns={\"Negative\" : \"Score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_df = pos_df.rename(columns={\"Positive\" : \"Score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df = pd.concat([pos_df, neg_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_df = combined_df.reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length= combined_df.reviews.map(lambda x: len(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(analyzer='word', ngram_range=(1,1),\n",
    "                      token_pattern=r'\\b\\w{1,}\\b', min_df=27,\n",
    "                      strip_accents='ascii', encoding='utf-8',\n",
    "                      stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect.fit(combined_df['reviews'])\n",
    "word_dict = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8073"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json = json.dumps(word_dict, cls=MyEncoder)\n",
    "#json = json.dumps(dict)\n",
    "f = open(\"/output/google_testdic.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()\n",
    "\n",
    "# loaded_words = json.loads(words)\n",
    "# type(words) #Output str\n",
    "# type(loaded_words) #Output dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_sentence(text):\n",
    "    result = []\n",
    "    arr = text_to_word_sequence(text, lower=True, split=\" \")\n",
    "    for word in arr:\n",
    "        w = encode_word(word)\n",
    "        if w is not None:\n",
    "            result.append(w)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_word(word):\n",
    "    if word not in word_dict:\n",
    "        return None\n",
    "    return word_dict[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(max_len):\n",
    "    Xts = combined_df[\"reviews\"].values\n",
    "    arr = []\n",
    "    for text in Xts:\n",
    "        arr.append(encode_sentence(text))\n",
    "    X = sequence.pad_sequences(arr, maxlen=max_len)\n",
    "    y = combined_df[\"Score\"].values\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling1D, Conv1D, Flatten, Dropout, Dense\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(words, vec_len, review_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(words, vec_len, input_length=review_len))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv1D(32, 3, padding=\"same\"))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(16, 3, padding=\"same\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(100, activation=\"sigmoid\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "version = 4\n",
    "words = len(word_dict)\n",
    "review_len = 1000\n",
    "vec_len = 300\n",
    "patience = 5\n",
    "batch_size = 40\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "X, y = build_dataset(review_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 300)         2421900   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000, 300)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1000, 32)          28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 16)           1552      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               800100    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 3,252,485\n",
      "Trainable params: 3,252,485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = build_model(words, vec_len, review_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stopping_monitor = EarlyStopping(patience=patience, monitor=\"loss\", mode=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "74s - loss: 0.2219 - acc: 0.9083 - val_loss: 0.2310 - val_acc: 0.8997\n",
      "Epoch 2/3\n",
      "33s - loss: 0.1191 - acc: 0.9561 - val_loss: 0.2443 - val_acc: 0.8940\n",
      "Epoch 3/3\n",
      "33s - loss: 0.0774 - acc: 0.9718 - val_loss: 0.2548 - val_acc: 0.9179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f694c3e0828>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "model.fit(X, y, epochs=epochs, callbacks=[early_stopping_monitor], batch_size=batch_size, verbose=2, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_builder = tf.saved_model.builder.SavedModelBuilder(\"GoogleTestModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'input': tf.saved_model.utils.build_tensor_info(model.input)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = {\n",
    "    'batch': tf.saved_model.utils.build_tensor_info(model.output)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signature_def = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "model_builder.add_meta_graph_and_variables(\n",
    "    K.get_session(),\n",
    "    tags=[tf.saved_model.tag_constants.SERVING],\n",
    "    signature_def_map={tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature_def}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'GoogleTestModel/saved_model.pb'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'GoogleTestModel/saved_model.pb'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.preprocessing import sequence\n",
    "# from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_batch(arr):\n",
    "    result = []\n",
    "    for sentence in arr:\n",
    "        result.append(encode_sentence(sentence))\n",
    "    return sequence.pad_sequences(result, maxlen=review_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_batch(arr):\n",
    "    batch = encode_batch(arr)\n",
    "    result = model.predict(batch, batch_size=len(batch), verbose=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.80668312]\n",
      " [ 0.82716978]\n",
      " [ 0.74110323]\n",
      " [ 0.94436091]\n",
      " [ 0.06486244]\n",
      " [ 0.06973273]\n",
      " [ 0.56603307]\n",
      " [ 0.56603307]]\n"
     ]
    }
   ],
   "source": [
    "print(predict_batch([\n",
    "\"yes\",\n",
    "\"good\",\n",
    "\"this is the best thing ever\",\n",
    "\"nice\",\n",
    "\"bad\",\n",
    "\"such a horrible judgement\",\n",
    "\"no\",\n",
    "\"shitty\"\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7682057]]\n"
     ]
    }
   ],
   "source": [
    "print(predict_batch([\"The rooms are big, the general set up of the outside is great, good colors, nice design but the food in the water trough and the breakfast are very average. The free breakfast is very basic with over cooked and crumbly scrambled eggs, cheap bread and flavored yogurt, very disappointing for a room at over 300 dollars. No real info from front desk for transport to airport or downtown.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00188351]]\n"
     ]
    }
   ],
   "source": [
    "print(predict_batch([\"The door to my room was left open by housekeeping and my computer was stolen. Management swore up and down that they would make things right ?!?! After being asked my story and made to send invoices the Insurance refused any culpable negligence...management quickly followed suit and refused to help i anyway.This MOTEL has declined quickly and become very dilapidated in a short time because of poor maintenance(my room safe was broken) there are cockroaches in bathroom. Do not stay here.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.98797995]]\n"
     ]
    }
   ],
   "source": [
    "print(predict_batch([\"My family and I stayed at this hotel last weekend for a football game. Location is close to the university and easy access to I-35. Staff was friendly and offered me a late checkout, which most hotels are not willing to do. Room is spacious and there is a full kitchen, though we did not need it for this trip. We will choose this hotel again the next time we are on town.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #save model\n",
    "# model.save(\"/output/optimalfloyds3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
